---
layout: page
title: research
permalink: /research/
nav: true
nav_order: 2
# dropdown: true
# children: 
#     - title: Co-Well Lab
#       permalink: /co-well/
#     - title: divider
#     - title: NLP-X Lab
#       permalink: /nlp-x/
#     - title: divider
#     - title: Sociolinguistics
#       permalink: /sociolinguistics/
#     - title: divider
#     - title: CoNTRoL Lab
#       permalink: /control/
---

<h1 style="color: rgb(166, 197, 247);">Co-Well Lab </h1>
<h3 style="color: rgb(166, 197, 247);"> Technology and Contraception Responsibility (2021 - 2023)</h3>
<h4> Publications: Planned EMNLP 2024 Submission</h4>
I have had the pleasure of working with Dr. Wei Xu in her [NLP-X Lab](https://cocoxu.github.io/) since Spring 2022. [Authorship](https://arxiv.org/abs/2209.06869) is the systematic study of persistent stylistic qualities behind documents written from the same source. While authorship is a broad research area, there have been few papers on more "real-world" authorship applications. Currently, I am investigating how noisy, multi-genre authorship setups - such as sourcing documents from several different social media platforms - fare against current SOTA authorship models and how to better improve upon the design in a cross-domain environment. In summary, I've found that effective authorship models in a single-domain experimental setup, such as the Transformer-based [BertAA](https://aclanthology.org/2020.icon-main.16/) or the more traditional N-gram model, are unable to find success in a multi-genre setting. I am currently designing new datasets and models that tackle this problem from a new angle, which will be released publicly in a future publication.
<br/><br/>
<h3 style="color: rgb(166, 197, 247);"> Strength-based Chatbot for Neurodiverse Job-Seekers (2023 - present)</h3>
<h4> Publications: Planned EMNLP 2024 Submission</h4>
I have had the pleasure of working with Dr. Wei Xu in her [NLP-X Lab](https://cocoxu.github.io/) since Spring 2022. [Authorship](https://arxiv.org/abs/2209.06869) is the systematic study of persistent stylistic qualities behind documents written from the same source. While authorship is a broad research area, there have been few papers on more "real-world" authorship applications. Currently, I am investigating how noisy, multi-genre authorship setups - such as sourcing documents from several different social media platforms - fare against current SOTA authorship models and how to better improve upon the design in a cross-domain environment. In summary, I've found that effective authorship models in a single-domain experimental setup, such as the Transformer-based [BertAA](https://aclanthology.org/2020.icon-main.16/) or the more traditional N-gram model, are unable to find success in a multi-genre setting. I am currently designing new datasets and models that tackle this problem from a new angle, which will be released publicly in a future publication.
<br/><br/><br/>
<h1 style="color: rgb(156,88,204);">NLP-X Lab </h1>
<h3 style="color: rgb(156,88,204);"> Authorship and Stylistics (2022 - present)</h3>
<h4> Publications: Planned EMNLP 2024 Submission</h4>


I have had the pleasure of working with Dr. Wei Xu in her [NLP-X Lab](https://cocoxu.github.io/) since Spring 2022. [Authorship](https://arxiv.org/abs/2209.06869) is the systematic study of persistent stylistic qualities behind documents written from the same source. While authorship is a broad research area, there have been few papers on more "real-world" authorship applications. Currently, I am investigating how noisy, multi-genre authorship setups - such as sourcing documents from several different social media platforms - fare against current SOTA authorship models and how to better improve upon the design in a cross-domain environment. In summary, I've found that effective authorship models in a single-domain experimental setup, such as the Transformer-based [BertAA](https://aclanthology.org/2020.icon-main.16/) or the more traditional N-gram model, are unable to find success in a multi-genre setting. I am currently designing new datasets and models that tackle this problem from a new angle, which will be released publicly in a future publication.

<br/><br/><br/>
<h1 style="color: rgb(219,163,22);"> Sociolinguistics Research </h1>
<h3 style="color: rgb(219,163,22);"> Language and Politics in the New South (2021 - 2022)</h3>
<h4> Publications: Planned EMNLP 2024 Submission</h4>

I have had the pleasure of working with Dr. Wei Xu in her [NLP-X Lab](https://cocoxu.github.io/) since Spring 2022. [Authorship](https://arxiv.org/abs/2209.06869) is the systematic study of persistent stylistic qualities behind documents written from the same source. While authorship is a broad research area, there have been few papers on more "real-world" authorship applications. Currently, I am investigating how noisy, multi-genre authorship setups - such as sourcing documents from several different social media platforms - fare against current SOTA authorship models and how to better improve upon the design in a cross-domain environment. In summary, I've found that effective authorship models in a single-domain experimental setup, such as the Transformer-based [BertAA](https://aclanthology.org/2020.icon-main.16/) or the more traditional N-gram model, are unable to find success in a multi-genre setting. I am currently designing new datasets and models that tackle this problem from a new angle, which will be released publicly in a future publication.

<h3 style="color: rgb(219,163,22);"> Automated Linguistics Transcription Pipeline (2022 - 2023)</h3>
<h4> Publications: Planned EMNLP 2024 Submission</h4>

I have had the pleasure of working with Dr. Wei Xu in her [NLP-X Lab](https://cocoxu.github.io/) since Spring 2022. [Authorship](https://arxiv.org/abs/2209.06869) is the systematic study of persistent stylistic qualities behind documents written from the same source. While authorship is a broad research area, there have been few papers on more "real-world" authorship applications. Currently, I am investigating how noisy, multi-genre authorship setups - such as sourcing documents from several different social media platforms - fare against current SOTA authorship models and how to better improve upon the design in a cross-domain environment. In summary, I've found that effective authorship models in a single-domain experimental setup, such as the Transformer-based [BertAA](https://aclanthology.org/2020.icon-main.16/) or the more traditional N-gram model, are unable to find success in a multi-genre setting. I am currently designing new datasets and models that tackle this problem from a new angle, which will be released publicly in a future publication.

<br/><br/><br/>
<h1 style="color: rgb(39,219,135);"> CoNTRoL Lab </h1>
<h3 style="color: rgb(39,219,135);"> Neural Zone State Performance (2021 - 2022)</h3>
<h4> Publications: Planned EMNLP 2024 Submission</h4>


I have had the pleasure of working with Dr. Wei Xu in her [NLP-X Lab](https://cocoxu.github.io/) since Spring 2022. [Authorship](https://arxiv.org/abs/2209.06869) is the systematic study of persistent stylistic qualities behind documents written from the same source. While authorship is a broad research area, there have been few papers on more "real-world" authorship applications. Currently, I am investigating how noisy, multi-genre authorship setups - such as sourcing documents from several different social media platforms - fare against current SOTA authorship models and how to better improve upon the design in a cross-domain environment. In summary, I've found that effective authorship models in a single-domain experimental setup, such as the Transformer-based [BertAA](https://aclanthology.org/2020.icon-main.16/) or the more traditional N-gram model, are unable to find success in a multi-genre setting. I am currently designing new datasets and models that tackle this problem from a new angle, which will be released publicly in a future publication.